{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Poemgenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHYI5dNj0mri"},"outputs":[],"source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Embedding\n","from keras.optimizers import RMSprop\n","from keras.utils import to_categorical\n","from keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.callbacks import EarlyStopping"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Preprocessing the data to be trained"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VWzLrqbT0q2-"},"outputs":[],"source":["# Load the data\n","with open('/content/drive/MyDrive/Colab Notebooks/modified_poems.txt', 'r') as file:\n","    text = file.read().lower()\n","\n","# Tokenize the data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts([text])\n","\n","# Convert text to sequences of integer values\n","sequences = tokenizer.texts_to_sequences([text])[0]\n","\n","# Prepare the dataset of input to output pairs encoded as integers\n","seq_length = 40\n","dataX = []\n","dataY = []\n","for i in range(0, len(sequences) - seq_length, 1):\n","    seq_in = sequences[i:i + seq_length]\n","    seq_out = sequences[i + seq_length]\n","    dataX.append([int(char) for char in seq_in])\n","    dataY.append(int(seq_out))\n","\n","# Total number of unique words\n","num_words = len(tokenizer.word_index) + 1\n","\n","# Prepare the dataset of input to output pairs encoded as integers\n","x = np.array(dataX)\n","y = to_categorical(dataY, num_classes=num_words)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Building the model "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":421113,"status":"ok","timestamp":1686357527406,"user":{"displayName":"Asterbu Creations","userId":"06874830667264696425"},"user_tz":-120},"id":"XT_O0kxUQ2ko","outputId":"9e737ca7-a00e-4df4-fdaa-ac06ef209b7d"},"outputs":[],"source":["# Build the model\n","model = Sequential()\n","model.add(Embedding(input_dim=num_words, output_dim=256, input_length=seq_length))\n","model.add(LSTM(400, return_sequences=True))\n","model.add(LSTM(400))\n","model.add(Dense(num_words, activation='softmax'))\n","\n","\n","# Compile the model\n","optimizer = RMSprop(learning_rate=0.01)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n","\n","\n","\n","# Prepare the callback\n","early_stopping = EarlyStopping(monitor='loss', patience=4)  # Stop if loss doesn't improve for 4 consecutive epochs\n","\n","# Add it to the `fit` method\n","model.fit(x, y, batch_size=50, epochs=75, callbacks=[early_stopping], validation_split=0.1)\n","\n","\n","model.save('modelword3.h5')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Using the model     \n","\n","Please use the model that I have selected.(Model name = \"modelword3.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3418,"status":"ok","timestamp":1686362556698,"user":{"displayName":"Asterbu Creations","userId":"06874830667264696425"},"user_tz":-120},"id":"t14ndZhYU7Ic","outputId":"a28aa67f-f14f-4b47-db7a-a7ca51b639bf"},"outputs":[],"source":["from keras.models import load_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","\n","def generate_seq(model, tokenizer, seed_text, seq_length, n_words):\n","    result = list()\n","    in_text = seed_text\n","    # generate a fixed number of words\n","    for _ in range(n_words):\n","        # encode the text as integer\n","        encoded = tokenizer.texts_to_sequences([in_text])[0]\n","        # truncate sequences to a fixed length\n","        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n","        # predict probabilities for each word\n","        yhat = model.predict(encoded, verbose=0).argmax(axis=-1)\n","        # map predicted word index to word\n","        out_word = ''\n","        for word, index in tokenizer.word_index.items():\n","            if index == yhat:\n","                out_word = word\n","                break\n","        # append to input\n","        in_text += ' ' + out_word\n","        result.append(out_word)\n","    return ' '.join(result)\n","\n","# load the model\n","model = load_model('path/to/themodel')\n","\n","# specify the seed text and the length of the generated sequence\n","seed_text = 'India '\n","seq_length = 40  # should be the same as seq_length during training\n","n_words = 22  # number of words to generate\n","\n","# generate new text\n","generated = generate_seq(model, tokenizer, seed_text, seq_length, n_words)\n","print(generated)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"S4DwMj6vVcUq"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMbvP+TUNSz7dNNmh8NQj0a","gpuType":"T4","machine_shape":"hm","mount_file_id":"1AEy4Qmvql5M7cck1DfBrSolsBG9ap2e5","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
