{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1Cw8S19Q6Nl0UJIV-9yGV088YU6ajrpaF","authorship_tag":"ABX9TyPto2kfxMx8S0ZLW61F+ZCb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"c-7qoV5RfY7o","executionInfo":{"status":"ok","timestamp":1686420823114,"user_tz":-120,"elapsed":3386,"user":{"displayName":"Asterbu Creations","userId":"06874830667264696425"}}},"outputs":[],"source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Embedding\n","from keras.optimizers import RMSprop\n","from keras.utils import to_categorical\n","from keras.preprocessing.text import Tokenizer\n","from keras.callbacks import EarlyStopping"]},{"cell_type":"code","source":["# Load the data\n","with open('/content/drive/MyDrive/Colab Notebooks/modified_poems.txt', 'r') as file:\n","    text = file.read().lower()\n","\n","# Tokenize the data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts([text])\n","\n","# Convert text to sequences of integer values\n","sequences = tokenizer.texts_to_sequences([text])[0]\n","\n","# Prepare the dataset of input to output pairs encoded as integers\n","seq_length = 40\n","dataX = []\n","dataY = []\n","for i in range(0, len(sequences) - seq_length, 1):\n","    seq_in = sequences[i:i + seq_length]\n","    seq_out = sequences[i + seq_length]\n","    dataX.append([int(char) for char in seq_in])\n","    dataY.append(int(seq_out))\n","\n","# Total number of unique words\n","num_words = len(tokenizer.word_index) + 1\n","\n","# Prepare the dataset of input to output pairs encoded as integers\n","x = np.array(dataX)\n","y = to_categorical(dataY, num_classes=num_words)\n"],"metadata":{"id":"5GiuMRF-gGVK","executionInfo":{"status":"ok","timestamp":1686420824677,"user_tz":-120,"elapsed":638,"user":{"displayName":"Asterbu Creations","userId":"06874830667264696425"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Build the model\n","model = Sequential()\n","model.add(Embedding(input_dim=num_words, output_dim=256, input_length=seq_length))\n","model.add(LSTM(440, return_sequences=True))\n","model.add(LSTM(440))\n","model.add(Dense(num_words, activation='softmax'))\n","\n","\n","# Compile the model\n","optimizer = RMSprop(learning_rate=0.001)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n","\n","\n","\n","# Prepare the callback\n","early_stopping = EarlyStopping(monitor='loss', patience=4)  # Stop if loss doesn't improve for 4 consecutive epochs\n","\n","# Add it to the `fit` method\n","model.fit(x, y, batch_size=30, epochs=120, callbacks=[early_stopping], validation_split=0.1)\n","\n","\n","model.save('poem4.h5')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82Tb8FVZgc_a","executionInfo":{"status":"ok","timestamp":1686426001110,"user_tz":-120,"elapsed":840527,"user":{"displayName":"Asterbu Creations","userId":"06874830667264696425"}},"outputId":"d253ca8f-336a-454b-afcb-e4d8495bef7f"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/120\n","760/760 [==============================] - 14s 12ms/step - loss: 6.1141 - val_loss: 6.1270\n","Epoch 2/120\n","760/760 [==============================] - 9s 12ms/step - loss: 5.6447 - val_loss: 5.9636\n","Epoch 3/120\n","760/760 [==============================] - 9s 12ms/step - loss: 5.3580 - val_loss: 5.8496\n","Epoch 4/120\n","760/760 [==============================] - 9s 11ms/step - loss: 5.0795 - val_loss: 5.7892\n","Epoch 5/120\n","760/760 [==============================] - 9s 11ms/step - loss: 4.9242 - val_loss: 5.7929\n","Epoch 6/120\n","760/760 [==============================] - 9s 12ms/step - loss: 4.7583 - val_loss: 5.7435\n","Epoch 7/120\n","760/760 [==============================] - 9s 11ms/step - loss: 4.5750 - val_loss: 5.7338\n","Epoch 8/120\n","760/760 [==============================] - 9s 12ms/step - loss: 4.3770 - val_loss: 5.7047\n","Epoch 9/120\n","760/760 [==============================] - 9s 12ms/step - loss: 4.1835 - val_loss: 5.5011\n","Epoch 10/120\n","760/760 [==============================] - 9s 11ms/step - loss: 3.9759 - val_loss: 5.6026\n","Epoch 11/120\n","760/760 [==============================] - 8s 11ms/step - loss: 3.8281 - val_loss: 5.7673\n","Epoch 12/120\n","760/760 [==============================] - 8s 11ms/step - loss: 3.6739 - val_loss: 6.1063\n","Epoch 13/120\n","760/760 [==============================] - 8s 11ms/step - loss: 3.5173 - val_loss: 5.8705\n","Epoch 14/120\n","760/760 [==============================] - 9s 12ms/step - loss: 3.3453 - val_loss: 6.8008\n","Epoch 15/120\n","760/760 [==============================] - 9s 12ms/step - loss: 3.2249 - val_loss: 6.2926\n","Epoch 16/120\n","760/760 [==============================] - 9s 12ms/step - loss: 3.1210 - val_loss: 6.4950\n","Epoch 17/120\n","760/760 [==============================] - 9s 12ms/step - loss: 2.9728 - val_loss: 6.6041\n","Epoch 18/120\n","760/760 [==============================] - 9s 12ms/step - loss: 2.8431 - val_loss: 6.7445\n","Epoch 19/120\n","760/760 [==============================] - 9s 12ms/step - loss: 2.7469 - val_loss: 7.1292\n","Epoch 20/120\n","760/760 [==============================] - 9s 12ms/step - loss: 2.6335 - val_loss: 7.4156\n","Epoch 21/120\n","760/760 [==============================] - 9s 12ms/step - loss: 2.4433 - val_loss: 7.4516\n","Epoch 22/120\n","760/760 [==============================] - 9s 11ms/step - loss: 2.3031 - val_loss: 7.6325\n","Epoch 23/120\n","760/760 [==============================] - 9s 12ms/step - loss: 2.2103 - val_loss: 7.9267\n","Epoch 24/120\n","760/760 [==============================] - 9s 11ms/step - loss: 2.1511 - val_loss: 7.5573\n","Epoch 25/120\n","760/760 [==============================] - 9s 12ms/step - loss: 2.0091 - val_loss: 7.7388\n","Epoch 26/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.9393 - val_loss: 7.9581\n","Epoch 27/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.9098 - val_loss: 8.2196\n","Epoch 28/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.8750 - val_loss: 8.3378\n","Epoch 29/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.7656 - val_loss: 8.5001\n","Epoch 30/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.7171 - val_loss: 8.6708\n","Epoch 31/120\n","760/760 [==============================] - 9s 11ms/step - loss: 1.6604 - val_loss: 8.6401\n","Epoch 32/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.6085 - val_loss: 8.6898\n","Epoch 33/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.5441 - val_loss: 9.1164\n","Epoch 34/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.4741 - val_loss: 8.9950\n","Epoch 35/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.4311 - val_loss: 9.1329\n","Epoch 36/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.3893 - val_loss: 9.2614\n","Epoch 37/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.3339 - val_loss: 9.3102\n","Epoch 38/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.3020 - val_loss: 9.2272\n","Epoch 39/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.2675 - val_loss: 9.2536\n","Epoch 40/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.2414 - val_loss: 9.4564\n","Epoch 41/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.2083 - val_loss: 9.5180\n","Epoch 42/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.1506 - val_loss: 9.3344\n","Epoch 43/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.1075 - val_loss: 9.6405\n","Epoch 44/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.0836 - val_loss: 9.6926\n","Epoch 45/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.0444 - val_loss: 9.9254\n","Epoch 46/120\n","760/760 [==============================] - 9s 12ms/step - loss: 1.0270 - val_loss: 9.8668\n","Epoch 47/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.9887 - val_loss: 9.6785\n","Epoch 48/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.9409 - val_loss: 10.0521\n","Epoch 49/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.9147 - val_loss: 9.7859\n","Epoch 50/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.8829 - val_loss: 10.0938\n","Epoch 51/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.8524 - val_loss: 10.1573\n","Epoch 52/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.8279 - val_loss: 10.3790\n","Epoch 53/120\n","760/760 [==============================] - 9s 11ms/step - loss: 0.7961 - val_loss: 10.4802\n","Epoch 54/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.7506 - val_loss: 10.4913\n","Epoch 55/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.7333 - val_loss: 10.5086\n","Epoch 56/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.7152 - val_loss: 10.8216\n","Epoch 57/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.6839 - val_loss: 11.0097\n","Epoch 58/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.6554 - val_loss: 11.0592\n","Epoch 59/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.6347 - val_loss: 11.3124\n","Epoch 60/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.6185 - val_loss: 11.5821\n","Epoch 61/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.6086 - val_loss: 11.3480\n","Epoch 62/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.5839 - val_loss: 11.6923\n","Epoch 63/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.5512 - val_loss: 11.4089\n","Epoch 64/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.5376 - val_loss: 11.5514\n","Epoch 65/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.5019 - val_loss: 11.7196\n","Epoch 66/120\n","760/760 [==============================] - 9s 11ms/step - loss: 0.4923 - val_loss: 11.9109\n","Epoch 67/120\n","760/760 [==============================] - 9s 11ms/step - loss: 0.4935 - val_loss: 12.0918\n","Epoch 68/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.4757 - val_loss: 11.7689\n","Epoch 69/120\n","760/760 [==============================] - 9s 11ms/step - loss: 0.4780 - val_loss: 11.9163\n","Epoch 70/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.4627 - val_loss: 12.0571\n","Epoch 71/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.4376 - val_loss: 12.4402\n","Epoch 72/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.4301 - val_loss: 12.5250\n","Epoch 73/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.4367 - val_loss: 12.6749\n","Epoch 74/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.4189 - val_loss: 12.9565\n","Epoch 75/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.4194 - val_loss: 12.7995\n","Epoch 76/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.4107 - val_loss: 12.7094\n","Epoch 77/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.4030 - val_loss: 12.8807\n","Epoch 78/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.4006 - val_loss: 13.0016\n","Epoch 79/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.4041 - val_loss: 12.9729\n","Epoch 80/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.4029 - val_loss: 13.2308\n","Epoch 81/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.3787 - val_loss: 13.3482\n","Epoch 82/120\n","760/760 [==============================] - 8s 11ms/step - loss: 0.3832 - val_loss: 13.2268\n","Epoch 83/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.3774 - val_loss: 13.2170\n","Epoch 84/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.3742 - val_loss: 13.5244\n","Epoch 85/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.3783 - val_loss: 13.5142\n","Epoch 86/120\n","760/760 [==============================] - 8s 11ms/step - loss: 0.3779 - val_loss: 13.9513\n","Epoch 87/120\n","760/760 [==============================] - 9s 11ms/step - loss: 0.3689 - val_loss: 14.2043\n","Epoch 88/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.3532 - val_loss: 13.7512\n","Epoch 89/120\n","760/760 [==============================] - 8s 11ms/step - loss: 0.3354 - val_loss: 13.8941\n","Epoch 90/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.3303 - val_loss: 13.8618\n","Epoch 91/120\n","760/760 [==============================] - 9s 11ms/step - loss: 0.3397 - val_loss: 14.1713\n","Epoch 92/120\n","760/760 [==============================] - 8s 11ms/step - loss: 0.3373 - val_loss: 13.9824\n","Epoch 93/120\n","760/760 [==============================] - 8s 11ms/step - loss: 0.3443 - val_loss: 14.2471\n","Epoch 94/120\n","760/760 [==============================] - 9s 12ms/step - loss: 0.3480 - val_loss: 13.9049\n"]}]},{"cell_type":"code","source":["from keras.models import load_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","def generate_seq(model, tokenizer, seed_text, seq_length, n_words):\n","    result = list()\n","    in_text = seed_text\n","    # generate a fixed number of words\n","    for _ in range(n_words):\n","        # encode the text as integer\n","        encoded = tokenizer.texts_to_sequences([in_text])[0]\n","        # truncate sequences to a fixed length\n","        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n","        # predict probabilities for each word\n","        yhat = model.predict(encoded, verbose=0).argmax(axis=-1)\n","        # map predicted word index to word\n","        out_word = ''\n","        for word, index in tokenizer.word_index.items():\n","            if index == yhat:\n","                out_word = word\n","                break\n","        # append to input\n","        in_text += ' ' + out_word\n","        result.append(out_word)\n","    return ' '.join(result)\n","\n","def format_poem(poem, words_per_line=5):\n","    words = poem.split()\n","    lines = [' '.join(words[i:i+words_per_line]) for i in range(0, len(words), words_per_line)]\n","    return '\\n'.join(lines)\n","\n","# load the model\n","model = load_model('/content/poem5.h5')\n","\n","# specify the seed text and the length of the generated sequence\n","seed_text = 'Uplifting '\n","seq_length = 40  # should be the same as seq_length during training\n","n_words = 25  # number of words to generate\n","\n","# generate new text\n","generated = generate_seq(model, tokenizer, seed_text, seq_length, n_words)\n","\n","# format the generated text\n","formatted_poem = format_poem(generated)\n","\n","print(formatted_poem)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubiEfO2BhPvi","executionInfo":{"status":"ok","timestamp":1686426120750,"user_tz":-120,"elapsed":3995,"user":{"displayName":"Asterbu Creations","userId":"06874830667264696425"}},"outputId":"b29856e6-93c2-4219-9664-cef1ae721940"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["where despair as their their\n","hand in war's realm sacrificial\n","love ripples unspoken life's place\n","together as strength we mend\n","uplifting spirits like hearts them\n"]}]},{"cell_type":"markdown","source":["poem.h5, epochs=12, bsize=50, Units=500\n","learning rate=0.01\n","\n","output:\n","and light and peace and\n","peace and peace and peace\n","and peace and peace and\n","peace and peace and peace\n","and peace\n","\n","poem.h5, epochs complete=35, bsize=50, Units = 300 learning rate=0.01\n","\n","output with seed text \"India\":\n","free whispers on hope's presence\n","is a melody sung by\n","a beacon of light in\n","the darkest night steady calm\n","and serene a promise of\n","\n","poem2.h5, epochs completed=35, bsize=50, Units = 400 learning rate=0.001\n","output with seed_text \"India\"\n","Epoch 70/75\n","456/456 [==============================] - 4s 9ms/step - loss: 0.2661 - val_loss: 9.1319\n","Epoch 71/75\n","456/456 [==============================] - 4s 9ms/step - loss: 0.2507 - val_loss: 9.1534\n","Epoch 72/75\n","456/456 [==============================] - 4s 9ms/step - loss: 0.2405 - val_loss: 9.1511\n","Epoch 73/75\n","456/456 [==============================] - 4s 9ms/step - loss: 0.2296 - val_loss: 9.2486\n","Epoch 74/75\n","456/456 [==============================] - 4s 9ms/step - loss: 0.2239 - val_loss: 9.3994\n","Epoch 75/75\n","456/456 [==============================] - 4s 9ms/step - loss: 0.2078 - val_loss: 9.4394\n","\n","we can see that the loss is getting better\n","\n","poem3.h5, epochs completed=92, bsize=40, Units = 440 learning rate=0.001\n","Epoch 92/120\n","570/570 [==============================] - 5s 9ms/step - loss: 0.0978 - val_loss: 11.7174\n","output with seed_text \"Uplifting Souls\"\n","\n","as radiant power day in\n","the realm of sunshine dreams\n","find their way a symphony\n","of possibilities where dreams can\n","near it fuels determination igniting"],"metadata":{"id":"W1sVkME0hp_Y"}}]}